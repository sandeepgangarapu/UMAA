# -*- coding: utf-8 -*-
"""pipeline

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1611dQ1XwCB3IFdI_ycHrYHT6imKGKu_D
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV, cross_validate
from imblearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import seaborn as sns



"""Load data"""

data = pd.read_csv('ata_for_model.csv')
valid_data = pd.read_csv('all_data_for_final.csv')


data = data.set_index('ID_DEMO')
valid_data = valid_data.set_index('ID_DEMO')
print(data.columns)

"""Seperate features and Target. Split the data into test and train sets"""

y = data['target'].ravel()
X = data.drop(['target'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)

"""Do preprocessing.

1. Impute missing values
2. Covers multi category variables into dummies
3. Scale all numeric variables 
4. PCA to reduce dimensions
5. SMOTE to remove imbalence

Use Logistic Regression as a baseline classifier
"""

numeric_features = ['AGE', 'UMN_event',
       'UMN_member', 'UMN_donor', 'UMN_volun', 'UMN_inform', 'UMN_loyalty',
       'UMN_avg_Annual_score_5_years', 'annual_member', 'life_member',
       'non_member', 'Learning_emails', 'Legislature_emails', 'Social_emails',
       'Sports_emails', 'general_ctr_emails', 'Learning_events',
       'Legislature_events', 'Networking_events', 'Other_events',
       'Social_events', 'Sports_events', 'total_type_person_events']
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())])

categorical_features = ['MARITAL_STATUS']
categorical_transformer = Pipeline(steps=[
                                          ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                                          ('onehot', OneHotEncoder(drop='first'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
       ('cat', categorical_transformer, categorical_features)
       ], n_jobs=-1)

pipe = Pipeline(steps=[('preprocessor', preprocessor),
                      ('smt', SMOTE(random_state=42, sampling_strategy=1)),
                      ('pca', PCA(n_components='mle')),
                      ('clf', GradientBoostingClassifier())])

"""Grid Search to search the hyperparameter space for Grandient Boosting classifier"""

param_grid = {
    'clf__kernel' : ['linear', 'rbf'],
    'clf__C' : np.linspace(0.1,1.2,12)
}

cv_grid = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1)

cv_grid.fit(X_train, y_train)
print("best_params",cv_grid.best_params_)
print("best_score", cv_grid.best_score_)

y_pred_prob = cv_grid.predict_proba(X_test)
y_pred = cv_grid.predict(X_test)

print("ROC Score", roc_auc_score(y_test, y_pred_prob[:,1]))

print(classification_report(y_test, y_pred))

# Get all measurement
columns_name = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy of Model is {0}'.format(round(accuracy,4)))
print(np.unique(y_test, return_counts=True))
print(confusion_matrix(y_test, y_pred))


sns.distplot(y_pred_prob[:,1], hist=True, kde=True, 
             bins=int(180/5), color = 'darkblue', 
             hist_kws={'edgecolor':'black'},
             kde_kws={'linewidth': 4})


a= cv_grid.predict_proba(valid_data)[:,1]

sns.distplot(a, hist=True, kde=True, 
             bins=int(180/5), color = 'darkblue', 
             hist_kws={'edgecolor':'black'},
             kde_kws={'linewidth': 4})