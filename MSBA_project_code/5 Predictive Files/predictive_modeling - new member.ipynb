{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIVE MODELINGS FOR NEW MEMBERSHIP ACQUISITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, you will see a new member acquisition model built on 400K Non-member in 2018, and we are predicting whether they became member in 2019. \n",
    "\n",
    "And this modeling scripts are built by CAL Team (Patrick Seng, Sam Musch, Pardha, Sameeksha and Shaco) collective efforts. For any issues and doubts, feel free to message us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below chunks are used for importing built-in packages for modeling training. You don't need to change the content. Just run it. These packages are like stored procedures in SQL, written functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3918c95da071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# import necessary libraries and specify that graphs should be plotted inline.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# from sklearn.tree import DecisionTreeClassifier, plot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sande\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '__check_build' from partially initialized module 'sklearn' (most likely due to a circular import) (c:\\users\\sande\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\__init__.py)"
     ],
     "ename": "ImportError",
     "evalue": "cannot import name '__check_build' from partially initialized module 'sklearn' (most likely due to a circular import) (c:\\users\\sande\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# import necessary libraries and specify that graphs should be plotted inline. \n",
    "# from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report,auc, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below chunk is used for importing the dataset for training.\n",
    "\n",
    "We basically need to files for model training:\n",
    "* Behavior related data, contains their engagement scores, past memberships, click through rate etc\n",
    "* Demographic related data, contains their demographic features including household income, age etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, when you need to read data from other files, you just need to change work directory. \n",
    "For example, instead of doing `pd.read_csv('Data_new_member_training_final.csv')`, \n",
    "you can do \n",
    "* `pd.read_csv('..\\5 Predictive Scriptis\\Data_new_member_training_final.csv')`\n",
    "\n",
    "Add the relative path in front of the file name.\n",
    "`..\\filename` leads you to the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# set work directory\n",
    "path = ''\n",
    "# load the data\n",
    "past_five = pd.read_csv(path + 'Data_new_member_training_final.csv')\n",
    "# demographic features\n",
    "individual = pd.read_csv('individual_info_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below chunk helps you to know the records in the data.\n",
    "You just need to have `filename.head(N)` to print the most top records in your data.\n",
    "\n",
    "If you want to see 10 records, just change the `number_of_records_to_print` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2cec72f78c07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnumber_of_records_to_print\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpast_five\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_records_to_print\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'past_five' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'past_five' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "number_of_records_to_print = 5\n",
    "past_five.head(number_of_records_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "individual.head(number_of_records_to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk below gives you what columns are included in your data file.\n",
    "\n",
    "Every time you want to see it, just do `file_name.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "past_five.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk helps you select needed columns for training. You can put/select columns that existed in the data by printing their columns like we did above, and then put those names in the brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**\n",
    "\n",
    "We exclude UMAA score since there is only 1 year data. Similarly, we use `click_through_rate` to measure how customer respond to our emails. IN addition, we alsu want to use sub-category engagement scores. \n",
    "\n",
    "We didn't use `UMN_MEMBER` score since we think this score doesn't truly reflect members' status. For example, for non-members, they definitely don't have a good UMN MEMBER score, but they are also likely to become a great member. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# decide to keep which columns\n",
    "individual = individual[['ID_DEMO','GENDER','AGE','HOUSEHOLD_INCOME','IN_TC_METRO_AREA','MEMBERSHIP_STATUS_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-677190dc8047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m past_five_new = past_five[['ID_DEMO','membership_LastYear','UMN_event','UMN_donor','UMN_volun', \n\u001b[0m\u001b[0;32m      2\u001b[0m                            \u001b[1;34m'UMN_inform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'UMN_loyalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'annual_years'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                            'nonmem_years','membership_TwoYearsAgo', 'general_ctr']]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'past_five' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'past_five' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "past_five_new = past_five[['ID_DEMO','membership_LastYear','UMN_event','UMN_donor','UMN_volun', \n",
    "                           'UMN_inform','UMN_loyalty', 'annual_years',\n",
    "                           'nonmem_years','membership_TwoYearsAgo', 'general_ctr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature called `past_member` to indicate whether this person was a member before. `Membership_status_code` indicated their past membership status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# No need to change this part in the future. The objective of this part is to craetea a new column\n",
    "# For people who were a past member, we use 1. Otherwise, we use 0.\n",
    "individual.loc[individual['MEMBERSHIP_STATUS_CODE'] == 'P','PAST_MEMBER'] = 1\n",
    "individual.drop(['MEMBERSHIP_STATUS_CODE'],axis = 1, inplace = True)\n",
    "individual.PAST_MEMBER.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those people who are annual member in 2018, we are predict their membership status in 2019. \n",
    "\n",
    "Once we have the model, train the model well, we will use it to predict the membership status for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# This chunk helps us select people who are annual member last year.\n",
    "# No need to change the this chunk in the future, just run it.\n",
    "past_five_new = past_five_new[past_five_new.membership_TwoYearsAgo == 'non-member']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk is similar to the `Join` function in SQL, we join two tables together to store information in only one table.\n",
    "\n",
    "**Parameters**\n",
    "* New table name is \"data\", `how = 'xxx'`, can be inner, left or right. \n",
    "* `on = 'column name'`,  the column you define as key\n",
    "* if you have multiple columns, you can do `left_on = ['column1',column2]`,`right_on = ['column1','column2']`\n",
    "\n",
    "For now, just run it, and no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.merge(past_five_new, individual, how = 'inner', on = 'ID_DEMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# There are unique 420749 Non-members in 2018\n",
    "data.ID_DEMO.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below chunk shows the missingness for each column. We want there is no missing values in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6a0ef670aff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "1 - data.count() / len(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is missing values in HOUSEHOLD_INCOME column. We removed those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep those records without missing values\n",
    "data = data[data.HOUSEHOLD_INCOME.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# print head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model isn't as smart as human. So sometime the model cannot understand all values.\n",
    "\n",
    "In this table, we need to do several things:\n",
    "* convert gender information from letters (M,F) to numbers (1,0)\n",
    "* convert IN_TC_METRO_AREA information from letters (Y,N) to numbers (1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data.GENDER = np.where(data.GENDER == 'M',1,0)\n",
    "data.IN_TC_METRO_AREA = np.where(data.IN_TC_METRO_AREA == 'Y',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# rename the column names\n",
    "# just want to keep them as UPPER case\n",
    "data.rename({'UMN_event':'UMN EVENT', \"UMN_member\":\"UMN MEMBER\",\"UMN_donor\":\"UMN DONOR\",\"UMN_volun\":\"UMN VOLUN\",\"UMN_inform\":\"UMN INFORM\",\\\n",
    "                   \"UMN_loyalty\":\"UMN LOYALTY\",'annual_years':'ANNUAL YEARS', 'life_years':\"LIFE YEARS\",\\\n",
    "       'nonmem_years':\"NOT MEMBER YEARS\", 'life_before_15_flag':\"IF LIFE MEMBER BEFORE 2015\", 'ctr':\"CLICK THROUGH RATE\",\\\n",
    "       'events_total':'EVENTS ATTENDED IN TOTAL','general_ctr':\"CLICK THROUGH RATE\"}, inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create another `table` named as `data_final` in case we do something wrong. So we create another table as our backup. When we want to go back to see our orignal data, we can just print `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-524d1c4fc7b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "data_training = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How we set the prediction flag**\n",
    "\n",
    "If the membership status in 2019 is a member, set the value to 1, else 0.\n",
    "\n",
    "* Membership status in 2019 is lifetime, then 1\n",
    "* Membership status in 2019 is annual member, then 1\n",
    "* Membership status in 2019 is not a member, then 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# create predict/target variable\n",
    "data_training['membership_LastYear'] = np.where(data_training.membership_LastYear == 'non-member',0,1)\n",
    "# rename the column\n",
    "data_training.rename(columns = {'membership_LastYear':'TARGET'}, inplace = True)\n",
    "# drop the column 'membership 2018'\n",
    "data_training.drop(['membership_TwoYearsAgo'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample The Data\n",
    "\n",
    "There is a **big challenge** for predictive modeling which is called imbalanced data. When there are overwhelming values than others, the model cannot perform very well. \n",
    "\n",
    "For example, there are 100 annual members, 95 of them will leave. A bad model can predict all of them that they won't renew their membership. However, we lose the opportunity to identify the remaining 5 who will ocnvert to a lifetime member while the model predicts 95% correct. \n",
    "\n",
    "So we need to deal with the resample technique to solve the imbalance issue.\n",
    "\n",
    "It's hard to explain the detail numbers in below chunks. They are selected based on testing. I would recommend for the future analysis, find someone who knows more about the resampling techniques to try a better parameter training.\n",
    "\n",
    "The below chunk is what we found work best for the current data. While the data growing, the parameters might change in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# only 0.8% of non-member convert to members in 2019\n",
    "# see the distribution of target variable\n",
    "# table_name. column_name . value_counts() and \n",
    "# then you can know how many people lables 1 and how many labels 0\n",
    "data_training.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that there are way more \"not member\" in our data. If the model simply predict all of them as not member, the model can still achieve a relative high accraucy, which is not we desired. \n",
    "\n",
    "In order to solve this imbalanced data issues, we decided to use resample techniques to simulate some new data and reduce the imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "more = data_training[data_training.TARGET == 0] # 449671 records\n",
    "less = data_training[data_training.TARGET == 1] # 3009 records\n",
    "\n",
    "df_unsampled_less = resample(less, replace = True, n_samples = 9000, random_state = 42)\n",
    "df_unsampled = pd.concat([more,df_unsampled_less])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# have the training and testing data readt\n",
    "y = df_unsampled['TARGET']\n",
    "x = df_unsampled.drop(['ID_DEMO','TARGET'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.33, random_state = 42, stratify = y)\n",
    "\n",
    "sm = SMOTE(random_state = 42, sampling_strategy= 0.50)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for Non-Member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**\n",
    "\n",
    "Below is a model called random forest.\n",
    "\n",
    "We train the model based on previous years data, and predict membership status next year. The below chunks trains the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# hyper parameters to tune\n",
    "# n_estimators = [100,300,500]\n",
    "# max_depth = [4,6,8]\n",
    "# min_samples_split = [2,4]\n",
    "# hyper = dict(n_estimators = n_estimators, max_depth = max_depth, \n",
    "#              min_samples_split = min_samples_split)\n",
    "# rf = RandomizedSearchCV(RandomForestClassifier(),hyper,cv = 3)\n",
    "\n",
    "# setup the model\n",
    "rf = RandomForestClassifier(n_estimators= 100, max_depth = 8,min_samples_split=2)\n",
    "# fit the model\n",
    "rf.fit(X_train,y_train)\n",
    "# predict the result\n",
    "pred_rf_no = rf.predict(X_test)\n",
    "pred_rf_no_all = rf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the model performance\n",
    "# the result will be printed out by running the below code\n",
    "print(classification_report(y_test, pred_rf_no))\n",
    "\n",
    "# Get all measurement\n",
    "columns_name = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "accuracy = accuracy_score(y_test, pred_rf_no)\n",
    "print('Accuracy of Decision Tree is {0}'.format(round(accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# output probability for new member acquisition\n",
    "predictions_rf_no = [round(1-i[0],3) for i in rf.predict_proba(x)]\n",
    "output_rf_no = pd.DataFrame({'ID_DEMO':df_unsampled['ID_DEMO'].values,\n",
    "                             'Prob_NotMember':predictions_rf_no,\n",
    "                            'Member_Label':pred_rf_no_all})\n",
    "# drop duplicates\n",
    "output_rf_no = output_rf_no.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "feature_importance = pd.DataFrame(rf.feature_importances_,\n",
    "                                 index = X_train.columns,\n",
    "                                 columns = ['importance']).sort_values('importance', \n",
    "                                                                       ascending = True)\n",
    "feature_importance.sort_values(by = 'importance', ascending = False).head()\n",
    "# output the feature importance for new member acquisition\n",
    "# feature_importance.sort_values(by = 'importance', ascending = False).to_csv('Feature_importance_New_member.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.barh(y = feature_importance.index, width = feature_importance.importance)\n",
    "plt.xlabel('Relative Feature Importance', fontsize =  16)\n",
    "plt.xticks(size = 14)\n",
    "plt.yticks(size = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Member Acquistion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# read data for prediction\n",
    "data_next = pd.read_csv(path + 'Data_new_member_future_prediction_final.csv')\n",
    "individual = pd.read_csv(path + 'individual_info_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# exclude people who are actually current members\n",
    "individual = individual[individual.MEMBERSHIP_STATUS_CODE != 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# select useful features from individual\n",
    "individual = individual[['ID_DEMO','GENDER','AGE',\n",
    "        'IN_TC_METRO_AREA', 'HOUSEHOLD_INCOME', 'MEMBERSHIP_STATUS_CODE',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# No need to change this part in the future. The objective of this part is to craetea a new column\n",
    "# For people who were a past member, we use 1. Otherwise, we use 0.\n",
    "individual.loc[individual['MEMBERSHIP_STATUS_CODE'] == 'P','PAST_MEMBER'] = 1\n",
    "individual.drop(['MEMBERSHIP_STATUS_CODE'],axis = 1, inplace = True)\n",
    "individual.PAST_MEMBER.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# merge demographic information\n",
    "data_prediction = pd.merge(data_next,individual, how = 'inner', on = 'ID_DEMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# check missing values\n",
    "data_prediction.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep those records without missing values\n",
    "data_prediction = data_prediction[data_prediction.HOUSEHOLD_INCOME.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# people who are annual member last year\n",
    "data_prediction = data_prediction[data_prediction.membership_LastYear == 'non-member']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# rename the column names\n",
    "# just want to keep them as UPPER case\n",
    "data_prediction.rename({'UMN_event':'UMN EVENT', \"UMN_member\":\"UMN MEMBER\",\"UMN_donor\":\"UMN DONOR\",\"UMN_volun\":\"UMN VOLUN\",\"UMN_inform\":\"UMN INFORM\",\\\n",
    "                   \"UMN_loyalty\":\"UMN LOYALTY\",'annual_years':'ANNUAL YEARS', 'life_years':\"LIFE YEARS\",\\\n",
    "       'nonmem_years':\"NOT MEMBER YEARS\", 'life_before_15_flag':\"IF LIFE MEMBER BEFORE 2015\", 'ctr':\"CLICK THROUGH RATE\",\\\n",
    "       'events_total':'EVENTS ATTENDED IN TOTAL','general_ctr':\"CLICK THROUGH RATE\"}, inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# similarly, we need to change the data values to the type that our model can recognize \n",
    "data_prediction.GENDER = np.where(data_prediction.GENDER == 'M',1,0)\n",
    "data_prediction.IN_TC_METRO_AREA = np.where(data_prediction.IN_TC_METRO_AREA == 'Y',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = data_prediction[['UMN EVENT', 'UMN DONOR', 'UMN VOLUN', 'UMN INFORM', 'UMN LOYALTY',\n",
    "       'ANNUAL YEARS', 'NOT MEMBER YEARS', 'CLICK THROUGH RATE', 'GENDER',\n",
    "       'AGE', 'HOUSEHOLD_INCOME', 'IN_TC_METRO_AREA', 'PAST_MEMBER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# previous model is called 'rf', then use rf to train the new model\n",
    "pred_rf_new = rf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Output prediction result.\n",
    "# the CSV file will generated in the end of this file, along with the probability of churn analysis.\n",
    "predictions_rf_new = [1 - round(i[0],3) for i in rf.predict_proba(x)]\n",
    "output_rf_new = pd.DataFrame({'ID_DEMO':data_prediction['ID_DEMO'].values,\n",
    "                               'Probability_NewMember':predictions_rf_new})\n",
    "# drop duplicates\n",
    "output_rf_new = output_rf_new.drop_duplicates()\n",
    "output_rf_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "individual = pd.read_csv(path + 'individual_info_cleaned.csv')\n",
    "output_rf_new = pd.merge(output_rf_new,individual, how = 'inner', on = 'ID_DEMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "output_rf_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "output_rf_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "output_rf_new.to_csv('Prediction_NewMember_Acquisition.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}